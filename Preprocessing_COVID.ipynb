{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Preprocessing_COVID.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPJx992VNBoS2Z+IxbsHGrw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/csetapan/MyResearchFile/blob/master/Preprocessing_COVID.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R7_oWiOLS_sa"
      },
      "source": [
        "import cv2\n",
        "import imageio\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VtMATZbqTkPr"
      },
      "source": [
        "img1 = cv2.imread(\"CT_COVID.png\")\n",
        "img = cv2.cvtColor(img1,cv2.COLOR_BGR2GRAY)\n",
        "img1 = img1[:,:,0]\n",
        "\n",
        "plt.imshow(img,cmap='gray')\n",
        "plt.axis('off')\n",
        "plt.show();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CztpOI5PT08Y"
      },
      "source": [
        "import cv2\n",
        "img = cv2.resize(img,(200,200))\n",
        "img = img[:,:,0]\n",
        "plt.hist(img.ravel(),bins=256)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-8L_ptbFUCG0"
      },
      "source": [
        "#img2 = cv2.imread(\"CT_COVID_fig2.png\")\n",
        "#img2 = cv2.cvtColor(img2,cv2.COLOR_BGR2GRAY)\n",
        "#plt.hist(img2.ravel(),bins=256);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oaifo82NURpk"
      },
      "source": [
        "#img3 = cv2.imread(\"CT_COVID_fig3.png\")\n",
        "#img3 = cv2.cvtColor(img3,cv2.COLOR_BGR2GRAY)\n",
        "#plt.hist(img3.ravel(),bins=256);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y4oHbmUhUWbq"
      },
      "source": [
        "#img4 = cv2.imread(\"CT_COVID_fig4.png\")\n",
        "#img4 = cv2.cvtColor(img4,cv2.COLOR_BGR2GRAY)\n",
        "#plt.hist(img4.ravel(),bins=256);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_j4U-kLjUbi4"
      },
      "source": [
        "ret,thresh = cv2.threshold(img,0,255,cv2.THRESH_BINARY)\n",
        "img_binary = img<thresh\n",
        "plt.imshow(img_binary,cmap='gray')\n",
        "plt.axis('off')\n",
        "plt.show();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HFqfxZ3QUbvB"
      },
      "source": [
        "from skimage.filters import try_all_threshold    \n",
        "fig,ax = try_all_threshold(img,verbose=False)\n",
        "#plt.imshow(fig,cmap='gray')\n",
        "plt.show();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_9c2bkLcUsp5"
      },
      "source": [
        "from skimage.filters import threshold_mean\n",
        "\n",
        "thresh = threshold_mean(img)\n",
        "img_binary = img<thresh\n",
        "plt.imshow(img_binary,cmap='gray')\n",
        "plt.axis('off')\n",
        "plt.show();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5c4aY9ItUxvU"
      },
      "source": [
        "img1 = 255-img\n",
        "plt.imshow(img1,cmap='gray')\n",
        "plt.show();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bXWy8ym_U3s4"
      },
      "source": [
        "import numpy as np\n",
        "img1 = np.where(img_binary>0,img,0)\n",
        "plt.imshow(img1,cmap='gray')\n",
        "plt.show();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cMORJt5HVAwY"
      },
      "source": [
        "img2=255.0-img1\n",
        "plt.imshow(img1,cmap='gray')\n",
        "plt.show();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NM9Nc4veVAz_"
      },
      "source": [
        "image1 = img2[55:130,35:85]\n",
        "image2 = img2[95:125,153:170]\n",
        "\n",
        "fig,(ax1,ax2)=plt.subplots(1,2,figsize=(10,5))\n",
        "\n",
        "ax1.imshow(image1,cmap='jet')\n",
        "ax2.imshow(image2,cmap='jet')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HXUN6Uw1VQh9"
      },
      "source": [
        "# Also wattershed  is used for segmentation using image boundary\n",
        "#Whwn many objects are very close to each other watershed technique is used to distingush the boundary\n",
        "# In watershed , we consider the gray image , wher each high intensites are considered as peaks and the low intensities are valley\n",
        "#Water of different color are poured in different valey and it rises to touch the peak, hence the water of different valley will\n",
        "# touch each other, this is considered as the bounary positions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i5ANqhplVfcS"
      },
      "source": [
        "from __future__ import division,print_function\n",
        "import cv2\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "from scipy import ndimage\n",
        "from skimage import measure,color,io\n",
        "from skimage.segmentation import clear_border\n",
        "#from scipy.ndimage import distance_transform_edt\n",
        "\n",
        "kernel = np.ones((5,5),np.uint8)\n",
        "\n",
        "#threshold value of the image by using otsu + binary threshold\n",
        "ret,thresh = cv2.threshold(img,0,255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n",
        "\n",
        "#MORPHOLOGICAL OPERATION TO REMOVE SMALL NOISE = opening\n",
        "#To remove holes we have used = closing\n",
        "opening = cv2.morphologyEx(thresh,cv2.MORPH_OPEN,kernel,iterations=2)\n",
        "\n",
        "#opening = clear_border(opening)\n",
        "\n",
        "Back_ground = cv2.erode(opening,kernel,iterations=1)\n",
        "plt.imshow(Back_ground,cmap='gray')\n",
        "#plt.title(\"Background\")\n",
        "plt.axis('off')\n",
        "plt.show();\n",
        "\n",
        "distance_transform = cv2.distanceTransform(opening,cv2.DIST_L2,3)\n",
        "\n",
        "ret2,Fore_ground = cv2.threshold(distance_transform,0.0999*distance_transform.max(),255,0)\n",
        "#sure_fg1 = 255.0-sure_fg\n",
        "Fore_ground = np.uint8(Fore_ground)\n",
        "\n",
        "plt.imshow(Fore_ground,cmap='gray')\n",
        "#plt.title(\"Sure Foreground\")\n",
        "plt.axis('off')\n",
        "plt.show();\n",
        "\n",
        "unknown = cv2.subtract(Back_ground,Fore_ground)\n",
        "\n",
        "ret2,markers = cv2.connectedComponents(Fore_ground)\n",
        "\n",
        "markers = markers + 10\n",
        "\n",
        "\n",
        "markers[unknown==255]=0\n",
        "\n",
        "plt.imshow(markers,cmap='jet')\n",
        "#plt.title(\"Markers\")\n",
        "plt.axis('off')\n",
        "plt.show();\n",
        "\n",
        "\n",
        "markers = cv2.watershed(img1,markers)\n",
        "#the boundary region will be marked -1\n",
        "#http://docs.opencv.org/3.3.1/d7/d1b//group-misc.html\n",
        "#let us color oundaries in yellow. Opencv assigns boundaries to -1 after watershed\n",
        "\n",
        "img1[markers==-1]=[0,255,255]\n",
        "img2 = color.label2rgb(markers,bg_label=0)\n",
        "\n",
        "plt.imshow(img)\n",
        "#plt.title(\"Overlay on Original Image\")\n",
        "plt.axis('off')\n",
        "plt.show();\n",
        "\n",
        "plt.imshow(img2)\n",
        "#plt.title(\"Infected Regions\")\n",
        "plt.axis('off')\n",
        "plt.show();"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}