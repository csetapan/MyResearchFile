{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MobileNet_SVC.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMQlkf8ZyBXVDlohfosbfaL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/csetapan/MyResearchFile/blob/master/MobileNet_SVC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QQ-4PJD-DwxZ"
      },
      "source": [
        "from tensorflow.keras.layers import Input, Lambda, Dense, Flatten\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "from tensorflow.keras.applications.mobilenet import MobileNet\n",
        "#from tensorflow.keras.applications.vgg16 import VGG16\n",
        "from tensorflow.keras.applications.inception_v3 import preprocess_input\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img\n",
        "from tensorflow.keras.models import Sequential\n",
        "import numpy as np\n",
        "from glob import glob\n",
        "import os\n",
        "import cv2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ikox2-LzEAle"
      },
      "source": [
        "CATEGORIES = ['CT_COVID','CT_NonCOVID']\n",
        "DATADIR = '/content/drive/MyDrive/Images-processed/train'\n",
        "SIZE = 256\n",
        "train_image = []\n",
        "train_labels = []\n",
        "for category in CATEGORIES:\n",
        "    path=os.path.join(DATADIR,category) # paths to CT_COVID or CT_NonCOVID directory\n",
        "    for img in os.listdir(path):\n",
        "        img_array=cv2.imread(os.path.join(path,img),cv2.IMREAD_COLOR)\n",
        "        #img_array=cv2.resize(img_array,(SIZE,SIZE))\n",
        "        try:\n",
        "          img_array=cv2.resize(img_array,(SIZE,SIZE))\n",
        "        except:\n",
        "          break\n",
        "        train_image.append(img_array)\n",
        "        train_labels.append(category)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7lmnaT_UUVID"
      },
      "source": [
        "CATEGORIES = ['CT_COVID','CT_NonCOVID']\n",
        "DATADIR = '/content/drive/MyDrive/Images-processed/test'\n",
        "test_image = []\n",
        "test_labels = []\n",
        "SIZE = 256\n",
        "for category in CATEGORIES:\n",
        "    path=os.path.join(DATADIR,category) # paths to CT_COVID or CT_NonCOVID directory\n",
        "    for img in os.listdir(path):\n",
        "        img_array=cv2.imread(os.path.join(path,img),cv2.IMREAD_COLOR)\n",
        "        img_array=cv2.resize(img_array,(SIZE,SIZE))\n",
        "        test_image.append(img_array)\n",
        "        test_labels.append(category)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cRlrIscnUWSM"
      },
      "source": [
        "#Convert lists to arrays                \n",
        "test_images = np.array(test_image)\n",
        "test_labels = np.array(test_labels)\n",
        "#Encode labels from text to integers.\n",
        "from sklearn import preprocessing\n",
        "le = preprocessing.LabelEncoder()\n",
        "le.fit(test_labels)\n",
        "test_labels_encoded = le.transform(test_labels)\n",
        "le.fit(train_labels)\n",
        "train_labels_encoded = le.transform(train_labels)\n",
        "\n",
        "#Split data into test and train datasets (already split but assigning to meaningful convention)\n",
        "x_train, y_train, x_test, y_test = train_image, train_labels_encoded, test_images, test_labels_encoded\n",
        "#x_train,y_train = train_image,train_labels_encoded"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Fs-xaDY4SWy"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZKDg4xjGUcm_"
      },
      "source": [
        "###################################################################\n",
        "from sklearn.model_selection import train_test_split\n",
        "# Normalize pixel values to between 0 and 1\n",
        "x_train = np.array(x_train)\n",
        "x_test = np.array(x_test)\n",
        "x_train, x_test = (x_train / 255.0), (x_test / 255.0)\n",
        "#x_train = (x_train / 255.0)\n",
        "\n",
        "#One hot encode y values for neural network. \n",
        "from keras.utils import to_categorical\n",
        "y_train_one_hot = to_categorical(y_train)\n",
        "y_test_one_hot = to_categorical(y_test)\n",
        "\n",
        "#x_train,x_test,y_train,y_test = train_test_split(x_train,y_train,test_size=0.2)\n",
        "\n",
        "#############################\n",
        "#Load model wothout classifier/fully connected layers\n",
        "MobileNet_model = MobileNet(weights='imagenet', include_top=False, input_shape=(SIZE, SIZE, 3))\n",
        "\n",
        "#Make loaded layers as non-trainable. This is important as we want to work with pre-trained weights\n",
        "for layer in MobileNet_model.layers:\n",
        "\tlayer.trainable = False\n",
        "    \n",
        "MobileNet_model.summary()  #Trainable parameters will be 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Eg2J_LC4sN8"
      },
      "source": [
        "#Now, let us use features from convolutional network for Model\n",
        "feature_extractor=MobileNet_model.predict(x_train)\n",
        "\n",
        "features = feature_extractor.reshape(feature_extractor.shape[0], -1)\n",
        "\n",
        "X_for_RF = features #This is our X input to Model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJLYCajT-_tf"
      },
      "source": [
        "#Send test data through same feature extractor process\n",
        "X_test_feature = MobileNet_model.predict(x_test)\n",
        "X_test_features = X_test_feature.reshape(X_test_feature.shape[0], -1)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TP5NCTtDUnY1"
      },
      "source": [
        "from sklearn.svm import SVC\n",
        "svc = SVC(random_state=42)\n",
        "svc.fit(X_for_RF, y_train)\n",
        "\n",
        "prediction_SVC = svc.predict(X_test_features)\n",
        "prediction_SVC = le.inverse_transform(prediction_SVC)\n",
        "print(\"Accuracy of SVC =\",metrics.accuracy_score(test_labels,prediction_SVC))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MzBumvPPUtl2"
      },
      "source": [
        "from sklearn.metrics import plot_roc_curve\n",
        "import matplotlib.pyplot as plt\n",
        "svc_disp = plot_roc_curve(svc, X_test_features, y_test)\n",
        "ax=plt.gca()\n",
        "#plt.show()\n",
        "#rfc_disp = plot_roc_curve(RF_model, X_test_features, y_test,ax = ax,alpha = 0.8)\n",
        "#svc_disp.plot(ax = ax, alpha=0.8)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_DU4wXb8ACk6"
      },
      "source": [
        "#Confusion Matrix - verify accuracy of each class in SVC\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "\n",
        "cm = confusion_matrix(test_labels, prediction_SVC)\n",
        "#print(cm)\n",
        "sns.heatmap(cm, annot=True)\n",
        "\n",
        "#Check results on a few select images\n",
        "n=np.random.randint(0, x_test.shape[0])\n",
        "img = x_test[n]\n",
        "plt.imshow(img)\n",
        "input_img = np.expand_dims(img, axis=0) #Expand dims so the input is (num images, x, y, c)\n",
        "input_img_feature=MobileNet_model.predict(input_img)\n",
        "input_img_features=input_img_feature.reshape(input_img_feature.shape[0], -1)\n",
        "prediction_F1 = svc.predict(input_img_features)[0] \n",
        "prediction_F1 = le.inverse_transform([prediction_F1])  #Reverse the label encoder to original name\n",
        "print(\"The prediction for this image is: \", prediction_F1)\n",
        "print(\"The actual label for this image is: \", test_labels[n])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}